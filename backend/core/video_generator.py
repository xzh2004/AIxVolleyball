"""
è§†é¢‘ç”Ÿæˆæ¨¡å— - ç”Ÿæˆéª¨æ¶å åŠ è§†é¢‘å’Œçº¯éª¨æ¶åŠ¨ç”»
"""
import cv2
import numpy as np
import tempfile
import os
from .pose_detector import PoseDetector


class VideoGenerator:
    """ç”Ÿæˆéª¨æ¶è§†é¢‘çš„ç±»"""
    
    def __init__(self):
        self.detector = PoseDetector()
        # MediaPipe éª¨æ¶è¿æ¥å®šä¹‰
        self.connections = [
            # èº¯å¹²
            (11, 12),  # å·¦è‚©-å³è‚©
            (11, 23),  # å·¦è‚©-å·¦é«‹
            (12, 24),  # å³è‚©-å³é«‹
            (23, 24),  # å·¦é«‹-å³é«‹
            
            # å·¦è‡‚
            (11, 13),  # å·¦è‚©-å·¦è‚˜
            (13, 15),  # å·¦è‚˜-å·¦è…•
            
            # å³è‡‚
            (12, 14),  # å³è‚©-å³è‚˜
            (14, 16),  # å³è‚˜-å³è…•
            
            # å·¦è…¿
            (23, 25),  # å·¦é«‹-å·¦è†
            (25, 27),  # å·¦è†-å·¦è¸
            
            # å³è…¿
            (24, 26),  # å³é«‹-å³è†
            (26, 28),  # å³è†-å³è¸
        ]
        
        # å…³é”®ç‚¹ç´¢å¼•æ˜ å°„
        self.landmark_map = {
            'left_shoulder': 11,
            'right_shoulder': 12,
            'left_elbow': 13,
            'right_elbow': 14,
            'left_wrist': 15,
            'right_wrist': 16,
            'left_hip': 23,
            'right_hip': 24,
            'left_knee': 25,
            'right_knee': 26,
            'left_ankle': 27,
            'right_ankle': 28,
        }
    
    def generate_video(self, video_path, output_path, video_type="overlay", max_frames=300):
        """
        ç»Ÿä¸€çš„è§†é¢‘ç”Ÿæˆæ¥å£
        
        Args:
            video_path: è¾“å…¥è§†é¢‘è·¯å¾„
            output_path: è¾“å‡ºè§†é¢‘è·¯å¾„
            video_type: è§†é¢‘ç±»å‹
                - "overlay": éª¨æ¶å åŠ 
                - "skeleton": çº¯éª¨æ¶
                - "comparison": å·¦å³å¯¹æ¯”
                - "trajectory": è½¨è¿¹è¿½è¸ª
            max_frames: æœ€å¤§å¤„ç†å¸§æ•°ï¼ˆé»˜è®¤300å¸§ï¼Œçº¦10-30ç§’è§†é¢‘ï¼‰
        
        Returns:
            str: è¾“å‡ºè§†é¢‘è·¯å¾„
        """
        from .sequence_analyzer import SequenceAnalyzer
        import subprocess
        import tempfile
        
        print(f"ğŸ¬ å¼€å§‹ç”Ÿæˆè§†é¢‘: {video_type}")
        
        # è¯»å–è§†é¢‘
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            raise ValueError(f"æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}")
        
        # è·å–è§†é¢‘ä¿¡æ¯
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fps = cap.get(cv2.CAP_PROP_FPS) or 10
        
        print(f"ğŸ“¹ è§†é¢‘ä¿¡æ¯: {total_frames} å¸§, {fps:.1f} FPS")
        
        # æå–å¸§ï¼ˆé™åˆ¶æ•°é‡ä»¥æé«˜é€Ÿåº¦ï¼‰
        frames = []
        frame_count = 0
        
        # å¦‚æœå¸§æ•°å¤ªå¤šï¼Œè¿›è¡Œé‡‡æ ·
        if total_frames > max_frames:
            frame_interval = total_frames // max_frames
            print(f"âš¡ å¸§æ•°è¿‡å¤šï¼Œæ¯ {frame_interval} å¸§é‡‡æ ·ä¸€æ¬¡")
        else:
            frame_interval = 1
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            if frame_count % frame_interval == 0:
                frames.append(frame)
                if len(frames) >= max_frames:
                    print(f"â¸ï¸ å·²è¾¾åˆ°æœ€å¤§å¸§æ•°é™åˆ¶: {max_frames}")
                    break
            
            frame_count += 1
        
        cap.release()
        
        if len(frames) == 0:
            raise ValueError("è§†é¢‘ä¸­æ²¡æœ‰æœ‰æ•ˆå¸§")
        
        print(f"âœ… æå–äº† {len(frames)} å¸§")
        
        # åˆ†æåºåˆ—ï¼ˆè¿™æ˜¯æœ€è€—æ—¶çš„éƒ¨åˆ†ï¼‰
        print("ğŸ” å¼€å§‹å§¿æ€åˆ†æ...")
        analyzer = SequenceAnalyzer()
        sequence_result = analyzer.analyze_sequence(frames)
        
        if not sequence_result.get("success", False):
            raise RuntimeError("åºåˆ—åˆ†æå¤±è´¥")
        
        print("âœ… å§¿æ€åˆ†æå®Œæˆ")
        
        # ç”Ÿæˆå¤„ç†åçš„å¸§
        print(f"ğŸ¨ å¼€å§‹ç”Ÿæˆ {video_type} è§†é¢‘...")
        
        if video_type == "overlay":
            processed_frames = self._generate_overlay_frames(frames, sequence_result)
        elif video_type == "skeleton":
            processed_frames = self._generate_skeleton_frames(sequence_result)
        elif video_type == "comparison":
            processed_frames = self._generate_comparison_frames(frames, sequence_result)
        elif video_type == "trajectory":
            processed_frames = self._generate_trajectory_frames(frames, sequence_result)
        else:
            raise ValueError(f"æœªçŸ¥çš„è§†é¢‘ç±»å‹: {video_type}")
        
        # ç›´æ¥ç”¨FFmpegæˆ–OpenCVå†™å…¥æµè§ˆå™¨å…¼å®¹æ ¼å¼
        final_result = self._write_web_compatible_video(processed_frames, output_path, fps)
        
        print(f"ğŸ‰ è§†é¢‘ç”Ÿæˆå®Œæˆ: {final_result}")
        return final_result
    
    def _generate_overlay_frames(self, frames, sequence_result):
        """ç”Ÿæˆéª¨æ¶å åŠ å¸§"""
        processed_frames = []
        for idx, frame in enumerate(frames):
            frame_data = sequence_result['frames_data'][idx]
            landmarks = frame_data['landmarks']
            overlay_frame = frame.copy()
            
            if landmarks:
                overlay_frame = self._draw_skeleton(overlay_frame, landmarks)
                cv2.putText(overlay_frame, f"Frame {idx + 1}/{len(frames)}", 
                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
            else:
                cv2.putText(overlay_frame, f"Frame {idx + 1}/{len(frames)} - No Pose", 
                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
            
            processed_frames.append(overlay_frame)
        return processed_frames
    
    def _generate_skeleton_frames(self, sequence_result, width=640, height=480):
        """ç”Ÿæˆçº¯éª¨æ¶å¸§"""
        processed_frames = []
        frames_data = sequence_result['frames_data']
        
        for idx, frame_data in enumerate(frames_data):
            skeleton_frame = np.ones((height, width, 3), dtype=np.uint8) * 255
            landmarks = frame_data['landmarks']
            
            if landmarks:
                skeleton_frame = self._draw_skeleton(
                    skeleton_frame, landmarks,
                    point_color=(0, 0, 255), line_color=(0, 0, 0),
                    point_radius=8, line_thickness=3
                )
            
            processed_frames.append(skeleton_frame)
        return processed_frames
    
    def _generate_comparison_frames(self, frames, sequence_result):
        """ç”Ÿæˆå·¦å³å¯¹æ¯”å¸§"""
        processed_frames = []
        height, width = frames[0].shape[:2]
        
        for idx, frame in enumerate(frames):
            # å·¦ä¾§ï¼šåŸè§†é¢‘
            left = frame.copy()
            
            # å³ä¾§ï¼šçº¯éª¨æ¶
            right = np.ones((height, width, 3), dtype=np.uint8) * 255
            frame_data = sequence_result['frames_data'][idx]
            landmarks = frame_data['landmarks']
            
            if landmarks:
                right = self._draw_skeleton(right, landmarks,
                    point_color=(0, 0, 255), line_color=(0, 0, 0),
                    point_radius=6, line_thickness=2)
            
            # æ‹¼æ¥
            comparison = np.hstack([left, right])
            processed_frames.append(comparison)
        return processed_frames
    
    def _generate_trajectory_frames(self, frames, sequence_result):
        """ç”Ÿæˆè½¨è¿¹è¿½è¸ªå¸§"""
        return self._generate_overlay_frames(frames, sequence_result)  # ç®€åŒ–ç‰ˆ
    
    def _write_web_compatible_video(self, frames, output_path, fps):
        """å†™å…¥æµè§ˆå™¨å…¼å®¹çš„è§†é¢‘"""
        import subprocess
        import tempfile
        import shutil
        
        if len(frames) == 0:
            raise ValueError("æ²¡æœ‰å¸§å¯ä»¥å†™å…¥")
        
        height, width = frames[0].shape[:2]
        
        # æ–¹æ³•1: ä½¿ç”¨FFmpegï¼ˆå›¾ç‰‡åºåˆ—æ–¹å¼ï¼Œæ›´ç¨³å®šï¼‰
        try:
            # æ£€æŸ¥FFmpeg
            result = subprocess.run(['ffmpeg', '-version'], capture_output=True, text=True, timeout=5)
            if result.returncode != 0:
                raise Exception("FFmpegä¸å¯ç”¨")
            
            print("ğŸ”„ ä½¿ç”¨FFmpegç”Ÿæˆæµè§ˆå™¨å…¼å®¹è§†é¢‘...")
            
            # åˆ›å»ºä¸´æ—¶ç›®å½•ä¿å­˜å¸§
            temp_dir = tempfile.mkdtemp()
            print(f"ğŸ“ ä¸´æ—¶ç›®å½•: {temp_dir}")
            
            try:
                # ä¿å­˜æ‰€æœ‰å¸§ä¸ºå›¾ç‰‡ï¼ˆé«˜è´¨é‡ï¼‰
                print(f"ğŸ’¾ ä¿å­˜ {len(frames)} å¸§ä¸ºé«˜è´¨é‡å›¾ç‰‡...")
                for i, frame in enumerate(frames):
                    if frame is None:
                        print(f"âš ï¸ ç¬¬{i}å¸§ä¸ºNoneï¼Œè·³è¿‡")
                        continue
                    frame_path = os.path.join(temp_dir, f'frame_{i:06d}.png')
                    # ä½¿ç”¨PNGå‹ç¼©ç­‰çº§0ï¼ˆæ— å‹ç¼©ï¼Œæœ€é«˜è´¨é‡ï¼‰
                    success = cv2.imwrite(frame_path, frame, [cv2.IMWRITE_PNG_COMPRESSION, 0])
                    if not success:
                        print(f"âš ï¸ ç¬¬{i}å¸§ä¿å­˜å¤±è´¥")
                
                print("âœ… å¸§ä¿å­˜å®Œæˆï¼Œå¼€å§‹FFmpegåˆæˆ...")
                
                # å°è¯•å¤šç§ç¼–ç æ–¹æ¡ˆï¼ˆé«˜è´¨é‡ï¼‰
                codecs = [
                    ('h264_hq', ['-c:v', 'h264', '-pix_fmt', 'yuv420p', '-b:v', '5M']),  # H.264é«˜ç ç‡
                    ('h264', ['-c:v', 'h264', '-pix_fmt', 'yuv420p']),  # H.264æ ‡å‡†
                    ('mpeg4_hq', ['-c:v', 'mpeg4', '-q:v', '2', '-pix_fmt', 'yuv420p']),  # MPEG4é«˜è´¨é‡
                    ('mpeg4', ['-c:v', 'mpeg4', '-q:v', '5'])  # MPEG4æ ‡å‡†
                ]
                
                result = None
                for codec_name, codec_args in codecs:
                    cmd = [
                        'ffmpeg', '-y',
                        '-framerate', str(fps),
                        '-i', os.path.join(temp_dir, 'frame_%06d.png')
                    ] + codec_args + [output_path]
                    
                    print(f"ğŸ¬ å°è¯•ç¼–ç å™¨: {codec_name}")
                    result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)
                    
                    if result.returncode == 0 and os.path.exists(output_path):
                        print(f"âœ… ä½¿ç”¨ {codec_name} ç¼–ç æˆåŠŸ")
                        break
                    else:
                        print(f"âš ï¸ {codec_name} å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ª...")
                        if os.path.exists(output_path):
                            os.remove(output_path)
                
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                print("ğŸ—‘ï¸ æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
                shutil.rmtree(temp_dir)
                
                if result.returncode == 0 and os.path.exists(output_path):
                    print("âœ… FFmpegç”ŸæˆæˆåŠŸï¼ˆH.264ç¼–ç ï¼‰")
                    return output_path
                else:
                    stderr = result.stderr if result.stderr else "æ— é”™è¯¯è¾“å‡º"
                    print(f"âš ï¸ FFmpegå¤±è´¥ (ä»£ç {result.returncode}): {stderr[:300]}")
                    
            except subprocess.TimeoutExpired:
                print("âš ï¸ FFmpegæ‰§è¡Œè¶…æ—¶")
                if os.path.exists(temp_dir):
                    shutil.rmtree(temp_dir)
                raise Exception("FFmpegè¶…æ—¶")
            except Exception as e:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if os.path.exists(temp_dir):
                    shutil.rmtree(temp_dir)
                raise e
                
        except Exception as e:
            print(f"â„¹ï¸ FFmpegæ–¹æ¡ˆå¤±è´¥: {str(e)}")
        
        # æ–¹æ³•2: ä½¿ç”¨OpenCVï¼ˆé™çº§æ–¹æ¡ˆï¼‰
        print("âš ï¸ å›é€€åˆ°OpenCVï¼Œè§†é¢‘å¯èƒ½æ— æ³•åœ¨æµè§ˆå™¨æ’­æ”¾")
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
        
        if not out.isOpened():
            raise RuntimeError("æ— æ³•åˆ›å»ºè§†é¢‘å†™å…¥å™¨")
        
        for frame in frames:
            out.write(frame)
        
        out.release()
        
        if os.path.exists(output_path) and os.path.getsize(output_path) > 0:
            print("âš ï¸ ä½¿ç”¨OpenCVç”Ÿæˆï¼Œæµè§ˆå™¨å¯èƒ½æ— æ³•æ’­æ”¾ï¼Œè¯·ä¸‹è½½æŸ¥çœ‹")
            return output_path
        else:
            raise RuntimeError("è§†é¢‘ç”Ÿæˆå¤±è´¥")
    
    def _convert_to_web_compatible(self, input_path, output_path):
        """
        å°†è§†é¢‘è½¬æ¢ä¸ºæµè§ˆå™¨å…¼å®¹çš„H.264æ ¼å¼
        
        Args:
            input_path: è¾“å…¥è§†é¢‘è·¯å¾„
            output_path: è¾“å‡ºè§†é¢‘è·¯å¾„
            
        Returns:
            str: è¾“å‡ºè§†é¢‘è·¯å¾„
        """
        try:
            # å°è¯•ä½¿ç”¨FFmpegï¼ˆå¦‚æœå¯ç”¨ï¼‰
            import subprocess
            
            # æ£€æŸ¥FFmpegæ˜¯å¦å¯ç”¨
            try:
                subprocess.run(['ffmpeg', '-version'], capture_output=True, check=True)
                has_ffmpeg = True
            except:
                has_ffmpeg = False
            
            if has_ffmpeg:
                # å°è¯•å¤šç§FFmpegå‘½ä»¤ï¼ˆå…¼å®¹ä¸åŒç‰ˆæœ¬ï¼‰
                
                # å‘½ä»¤1: å®Œæ•´å‚æ•°ï¼ˆé€‚ç”¨äºå®Œæ•´ç‰ˆFFmpegï¼‰
                cmd1 = [
                    'ffmpeg', '-y', '-i', input_path,
                    '-c:v', 'libx264',
                    '-preset', 'medium',
                    '-crf', '23',
                    '-pix_fmt', 'yuv420p',
                    '-movflags', '+faststart',
                    output_path
                ]
                
                # å‘½ä»¤2: åŸºç¡€å‚æ•°ï¼ˆé€‚ç”¨äºç²¾ç®€ç‰ˆFFmpegï¼‰
                cmd2 = [
                    'ffmpeg', '-y', '-i', input_path,
                    '-c:v', 'libx264',
                    '-pix_fmt', 'yuv420p',
                    '-movflags', '+faststart',
                    output_path
                ]
                
                # å‘½ä»¤3: æœ€ç®€å‚æ•°ï¼ˆæœ€å¤§å…¼å®¹æ€§ï¼‰
                cmd3 = [
                    'ffmpeg', '-y', '-i', input_path,
                    '-vcodec', 'libx264',
                    '-pix_fmt', 'yuv420p',
                    output_path
                ]
                
                # ä¾æ¬¡å°è¯•
                for i, cmd in enumerate([cmd1, cmd2, cmd3], 1):
                    result = subprocess.run(cmd, capture_output=True, text=True)
                    
                    if result.returncode == 0 and os.path.exists(output_path):
                        print(f"âœ… FFmpegè½¬æ¢æˆåŠŸï¼ˆæ–¹æ¡ˆ{i}ï¼‰")
                        # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                        if os.path.exists(input_path):
                            os.remove(input_path)
                        return output_path
                    elif i == 3:  # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥
                        print(f"âš ï¸ FFmpegæ‰€æœ‰æ–¹æ¡ˆéƒ½å¤±è´¥")
            
            # å¦‚æœFFmpegä¸å¯ç”¨ï¼Œä½¿ç”¨OpenCVé‡æ–°ç¼–ç 
            print("â„¹ï¸ ä½¿ç”¨OpenCVé‡æ–°ç¼–ç ...")
            cap = cv2.VideoCapture(input_path)
            fps = cap.get(cv2.CAP_PROP_FPS) or 10
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            
            # ä½¿ç”¨X264ç¼–ç å™¨
            fourcc = cv2.VideoWriter_fourcc(*'X264')
            out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
            
            if not out.isOpened():
                # å¦‚æœX264ä¸å¯ç”¨ï¼Œå°è¯•H264
                fourcc = cv2.VideoWriter_fourcc(*'H264')
                out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
            
            if out.isOpened():
                while True:
                    ret, frame = cap.read()
                    if not ret:
                        break
                    out.write(frame)
                
                cap.release()
                out.release()
                
                if os.path.exists(output_path) and os.path.getsize(output_path) > 0:
                    # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                    if os.path.exists(input_path):
                        os.remove(input_path)
                    return output_path
            
            # å¦‚æœæ‰€æœ‰è½¬æ¢éƒ½å¤±è´¥ï¼Œè¿”å›åŸå§‹æ–‡ä»¶
            print("âš ï¸ æ— æ³•è½¬æ¢ä¸ºH.264æ ¼å¼ï¼Œä½¿ç”¨åŸå§‹è§†é¢‘")
            if not os.path.exists(output_path):
                os.rename(input_path, output_path)
            return output_path
            
        except Exception as e:
            print(f"âš ï¸ è½¬æ¢è¿‡ç¨‹å‡ºé”™: {str(e)}")
            # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ–‡ä»¶
            if not os.path.exists(output_path) and os.path.exists(input_path):
                os.rename(input_path, output_path)
            return output_path
    
    def create_overlay_video(self, frames, sequence_result, output_path=None, fps=10):
        """
        åˆ›å»ºéª¨æ¶å åŠ è§†é¢‘ï¼ˆæ–¹æ¡ˆ1ï¼‰
        
        Args:
            frames: åŸå§‹è§†é¢‘å¸§åˆ—è¡¨
            sequence_result: åºåˆ—åˆ†æç»“æœï¼ˆåŒ…å«æ¯å¸§çš„landmarksï¼‰
            output_path: è¾“å‡ºè§†é¢‘è·¯å¾„ï¼ˆå¦‚æœä¸ºNoneåˆ™åˆ›å»ºä¸´æ—¶æ–‡ä»¶ï¼‰
            fps: è¾“å‡ºè§†é¢‘å¸§ç‡
            
        Returns:
            output_path: ç”Ÿæˆçš„è§†é¢‘æ–‡ä»¶è·¯å¾„
        """
        if output_path is None:
            # ä½¿ç”¨é¡¹ç›®ç›®å½•ä¸‹çš„outputæ–‡ä»¶å¤¹
            output_dir = 'output'
            if not os.path.exists(output_dir):
                os.makedirs(output_dir)
            output_path = os.path.join(output_dir, f'volleyball_overlay_{id(sequence_result)}.mp4')
        
        # è·å–è§†é¢‘å‚æ•°
        height, width = frames[0].shape[:2]
        
        # å°è¯•å¤šç§ç¼–ç æ ¼å¼ï¼Œç¡®ä¿å…¼å®¹æ€§
        fourcc_list = [
            cv2.VideoWriter_fourcc(*'mp4v'),  # MPEG-4
            cv2.VideoWriter_fourcc(*'avc1'),  # H.264
            cv2.VideoWriter_fourcc(*'XVID'),  # Xvid
        ]
        
        out = None
        for fourcc in fourcc_list:
            out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
            if out.isOpened():
                break
        
        if not out or not out.isOpened():
            raise RuntimeError("æ— æ³•åˆ›å»ºè§†é¢‘å†™å…¥å™¨ï¼Œè¯·æ£€æŸ¥OpenCVå®‰è£…")
        
        # å¤„ç†æ¯ä¸€å¸§
        for idx, frame in enumerate(frames):
            try:
                # è·å–è¯¥å¸§çš„landmarks
                frame_data = sequence_result['frames_data'][idx]
                landmarks = frame_data['landmarks']
                
                # å¤åˆ¶å¸§ï¼Œç¡®ä¿æ˜¯æ­£ç¡®çš„æ•°æ®ç±»å‹
                overlay_frame = frame.copy()
                
                # ç¡®ä¿å¸§æ˜¯BGRæ ¼å¼ï¼Œuint8ç±»å‹
                if overlay_frame.dtype != np.uint8:
                    overlay_frame = overlay_frame.astype(np.uint8)
                
                if landmarks:
                    # ç»˜åˆ¶éª¨æ¶
                    overlay_frame = self._draw_skeleton(overlay_frame, landmarks)
                    
                    # æ·»åŠ å¸§ä¿¡æ¯æ–‡å­—
                    cv2.putText(overlay_frame, f"Frame {idx + 1}/{len(frames)}", 
                               (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
                else:
                    # æœªæ£€æµ‹åˆ°å§¿æ€
                    cv2.putText(overlay_frame, f"Frame {idx + 1}/{len(frames)} - No Pose Detected", 
                               (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
                
                # å†™å…¥å¸§ï¼ˆä¸æ£€æŸ¥è¿”å›å€¼ï¼Œå› ä¸ºOpenCVåœ¨Windowsä¸Šè¿”å›å€¼ä¸å¯é ï¼‰
                out.write(overlay_frame)
                
            except Exception as e:
                # å¦‚æœå•å¸§å¤„ç†å¤±è´¥ï¼Œè®°å½•ä½†ç»§ç»­
                print(f"è­¦å‘Šï¼šå¤„ç†ç¬¬{idx+1}å¸§æ—¶å‡ºé”™: {str(e)}")
        
        # é‡Šæ”¾èµ„æº
        out.release()
        
        # éªŒè¯æ–‡ä»¶æ˜¯å¦ç”Ÿæˆ
        if not os.path.exists(output_path) or os.path.getsize(output_path) == 0:
            raise RuntimeError(f"è§†é¢‘æ–‡ä»¶ç”Ÿæˆå¤±è´¥: {output_path}")
        
        return output_path
    
    def create_skeleton_video(self, sequence_result, output_path=None, fps=10, 
                             width=640, height=480, bg_color=(255, 255, 255)):
        """
        åˆ›å»ºçº¯éª¨æ¶åŠ¨ç”»è§†é¢‘ï¼ˆæ–¹æ¡ˆ2ï¼‰
        
        Args:
            sequence_result: åºåˆ—åˆ†æç»“æœ
            output_path: è¾“å‡ºè§†é¢‘è·¯å¾„
            fps: è¾“å‡ºè§†é¢‘å¸§ç‡
            width: è§†é¢‘å®½åº¦
            height: è§†é¢‘é«˜åº¦
            bg_color: èƒŒæ™¯é¢œè‰² (B, G, R)
            
        Returns:
            output_path: ç”Ÿæˆçš„è§†é¢‘æ–‡ä»¶è·¯å¾„
        """
        if output_path is None:
            # ä½¿ç”¨é¡¹ç›®ç›®å½•ä¸‹çš„outputæ–‡ä»¶å¤¹
            output_dir = 'output'
            if not os.path.exists(output_dir):
                os.makedirs(output_dir)
            output_path = os.path.join(output_dir, f'volleyball_skeleton_{id(sequence_result)}.mp4')
        
        # å°è¯•å¤šç§ç¼–ç æ ¼å¼
        fourcc_list = [
            cv2.VideoWriter_fourcc(*'mp4v'),
            cv2.VideoWriter_fourcc(*'avc1'),
            cv2.VideoWriter_fourcc(*'XVID'),
        ]
        
        out = None
        for fourcc in fourcc_list:
            out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
            if out.isOpened():
                break
        
        if not out or not out.isOpened():
            raise RuntimeError("æ— æ³•åˆ›å»ºè§†é¢‘å†™å…¥å™¨")
        
        frames_data = sequence_result['frames_data']
        
        # å¤„ç†æ¯ä¸€å¸§
        for idx, frame_data in enumerate(frames_data):
            try:
                # åˆ›å»ºç™½è‰²èƒŒæ™¯
                skeleton_frame = np.ones((height, width, 3), dtype=np.uint8) * np.array(bg_color, dtype=np.uint8)
                
                landmarks = frame_data['landmarks']
                
                if landmarks:
                    # ç»˜åˆ¶éª¨æ¶ï¼ˆé»‘è‰²ï¼Œæ›´æ¸…æ™°ï¼‰
                    skeleton_frame = self._draw_skeleton(
                        skeleton_frame, 
                        landmarks,
                        point_color=(0, 0, 255),      # çº¢è‰²å…³é”®ç‚¹
                        line_color=(0, 0, 0),         # é»‘è‰²éª¨æ¶çº¿
                        point_radius=8,
                        line_thickness=3
                    )
                    
                    # æ·»åŠ æ ‡é¢˜å’Œå¸§ä¿¡æ¯
                    cv2.putText(skeleton_frame, "Skeleton Animation", 
                               (width//2 - 120, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 0), 2)
                    cv2.putText(skeleton_frame, f"Frame {idx + 1}/{len(frames_data)}", 
                               (10, height - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (100, 100, 100), 2)
                else:
                    # æœªæ£€æµ‹åˆ°å§¿æ€
                    cv2.putText(skeleton_frame, "No Pose Detected", 
                               (width//2 - 100, height//2), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2)
                    cv2.putText(skeleton_frame, f"Frame {idx + 1}/{len(frames_data)}", 
                               (10, height - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (100, 100, 100), 2)
                
                # å†™å…¥å¸§ï¼ˆä¸æ£€æŸ¥è¿”å›å€¼ï¼‰
                out.write(skeleton_frame)
                
            except Exception as e:
                print(f"è­¦å‘Šï¼šå¤„ç†ç¬¬{idx+1}å¸§æ—¶å‡ºé”™: {str(e)}")
        
        # é‡Šæ”¾èµ„æº
        out.release()
        
        # éªŒè¯æ–‡ä»¶
        if not os.path.exists(output_path) or os.path.getsize(output_path) == 0:
            raise RuntimeError(f"è§†é¢‘æ–‡ä»¶ç”Ÿæˆå¤±è´¥: {output_path}")
        
        return output_path
    
    def create_side_by_side_video(self, frames, sequence_result, output_path=None, fps=10):
        """
        åˆ›å»ºå·¦å³å¯¹æ¯”è§†é¢‘ï¼šå·¦ä¾§åŸè§†é¢‘ï¼Œå³ä¾§çº¯éª¨æ¶
        
        Args:
            frames: åŸå§‹è§†é¢‘å¸§åˆ—è¡¨
            sequence_result: åºåˆ—åˆ†æç»“æœ
            output_path: è¾“å‡ºè§†é¢‘è·¯å¾„
            fps: è¾“å‡ºè§†é¢‘å¸§ç‡
            
        Returns:
            output_path: ç”Ÿæˆçš„è§†é¢‘æ–‡ä»¶è·¯å¾„
        """
        if output_path is None:
            # ä½¿ç”¨é¡¹ç›®ç›®å½•ä¸‹çš„outputæ–‡ä»¶å¤¹
            output_dir = 'output'
            if not os.path.exists(output_dir):
                os.makedirs(output_dir)
            output_path = os.path.join(output_dir, f'volleyball_comparison_{id(sequence_result)}.mp4')
        
        # è·å–è§†é¢‘å‚æ•°
        height, width = frames[0].shape[:2]
        
        # å°è¯•å¤šç§ç¼–ç æ ¼å¼
        fourcc_list = [
            cv2.VideoWriter_fourcc(*'mp4v'),
            cv2.VideoWriter_fourcc(*'avc1'),
            cv2.VideoWriter_fourcc(*'XVID'),
        ]
        
        out = None
        for fourcc in fourcc_list:
            out = cv2.VideoWriter(output_path, fourcc, fps, (width * 2, height))
            if out.isOpened():
                break
        
        if not out or not out.isOpened():
            raise RuntimeError("æ— æ³•åˆ›å»ºè§†é¢‘å†™å…¥å™¨")
        
        frames_data = sequence_result['frames_data']
        
        # å¤„ç†æ¯ä¸€å¸§
        for idx, frame in enumerate(frames):
            landmarks = frames_data[idx]['landmarks']
            
            # å·¦ä¾§ï¼šåŸè§†é¢‘ + éª¨æ¶
            left_frame = frame.copy()
            if landmarks:
                left_frame = self._draw_skeleton(left_frame, landmarks)
            cv2.putText(left_frame, "Original + Skeleton", 
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            # å³ä¾§ï¼šçº¯éª¨æ¶
            right_frame = np.ones((height, width, 3), dtype=np.uint8) * 255
            if landmarks:
                right_frame = self._draw_skeleton(
                    right_frame, 
                    landmarks,
                    point_color=(0, 0, 255),
                    line_color=(0, 0, 0),
                    point_radius=8,
                    line_thickness=3
                )
            cv2.putText(right_frame, "Skeleton Only", 
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)
            
            # åˆå¹¶å·¦å³ç”»é¢
            combined_frame = np.hstack([left_frame, right_frame])
            
            # æ·»åŠ å¸§ä¿¡æ¯
            cv2.putText(combined_frame, f"Frame {idx + 1}/{len(frames)}", 
                       (width - 150, height - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            
            # å†™å…¥å¸§ï¼ˆä¸æ£€æŸ¥è¿”å›å€¼ï¼‰
            out.write(combined_frame)
        
        # é‡Šæ”¾èµ„æº
        out.release()
        
        # éªŒè¯æ–‡ä»¶
        if not os.path.exists(output_path) or os.path.getsize(output_path) == 0:
            raise RuntimeError(f"è§†é¢‘æ–‡ä»¶ç”Ÿæˆå¤±è´¥: {output_path}")
        
        return output_path
    
    def _draw_skeleton(self, frame, landmarks, point_color=(0, 255, 0), 
                      line_color=(0, 255, 0), point_radius=5, line_thickness=2):
        """
        åœ¨å¸§ä¸Šç»˜åˆ¶éª¨æ¶
        
        Args:
            frame: è¦ç»˜åˆ¶çš„å¸§
            landmarks: å…³é”®ç‚¹å­—å…¸
            point_color: å…³é”®ç‚¹é¢œè‰²
            line_color: éª¨æ¶çº¿é¢œè‰²
            point_radius: å…³é”®ç‚¹åŠå¾„
            line_thickness: éª¨æ¶çº¿ç²—ç»†
            
        Returns:
            ç»˜åˆ¶åçš„å¸§
        """
        height, width = frame.shape[:2]
        
        # åˆ›å»ºå…³é”®ç‚¹ä½ç½®æ•°ç»„ï¼ˆç”¨äºè¿çº¿ï¼‰
        points = {}
        for name, idx in self.landmark_map.items():
            if name in landmarks:
                lm = landmarks[name]
                x = int(lm['x'] * width)
                y = int(lm['y'] * height)
                visibility = lm.get('visibility', 1.0)
                
                # åªç»˜åˆ¶å¯è§åº¦é«˜çš„ç‚¹
                if visibility > 0.5:
                    points[idx] = (x, y)
        
        # ç»˜åˆ¶è¿æ¥çº¿
        for connection in self.connections:
            start_idx, end_idx = connection
            if start_idx in points and end_idx in points:
                cv2.line(frame, points[start_idx], points[end_idx], 
                        line_color, line_thickness)
        
        # ç»˜åˆ¶å…³é”®ç‚¹
        for idx, point in points.items():
            cv2.circle(frame, point, point_radius, point_color, -1)
            # æ·»åŠ ç‚¹çš„æ ‡æ³¨ï¼ˆå¯é€‰ï¼‰
            # cv2.putText(frame, str(idx), point, cv2.FONT_HERSHEY_SIMPLEX, 0.3, (255, 255, 255), 1)
        
        return frame
    
    def create_trajectory_video(self, frames, sequence_result, output_path=None, fps=10):
        """
        åˆ›å»ºè½¨è¿¹è¿½è¸ªè§†é¢‘ï¼šæ˜¾ç¤ºå…³é”®ç‚¹çš„è¿åŠ¨è½¨è¿¹
        
        Args:
            frames: åŸå§‹è§†é¢‘å¸§åˆ—è¡¨
            sequence_result: åºåˆ—åˆ†æç»“æœ
            output_path: è¾“å‡ºè§†é¢‘è·¯å¾„
            fps: è¾“å‡ºè§†é¢‘å¸§ç‡
            
        Returns:
            output_path: ç”Ÿæˆçš„è§†é¢‘æ–‡ä»¶è·¯å¾„
        """
        if output_path is None:
            # ä½¿ç”¨é¡¹ç›®ç›®å½•ä¸‹çš„outputæ–‡ä»¶å¤¹
            output_dir = 'output'
            if not os.path.exists(output_dir):
                os.makedirs(output_dir)
            output_path = os.path.join(output_dir, f'volleyball_trajectory_{id(sequence_result)}.mp4')
        
        # è·å–è§†é¢‘å‚æ•°
        height, width = frames[0].shape[:2]
        
        # å°è¯•å¤šç§ç¼–ç æ ¼å¼
        fourcc_list = [
            cv2.VideoWriter_fourcc(*'mp4v'),
            cv2.VideoWriter_fourcc(*'avc1'),
            cv2.VideoWriter_fourcc(*'XVID'),
        ]
        
        out = None
        for fourcc in fourcc_list:
            out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
            if out.isOpened():
                break
        
        if not out or not out.isOpened():
            raise RuntimeError("æ— æ³•åˆ›å»ºè§†é¢‘å†™å…¥å™¨")
        
        # æ”¶é›†è½¨è¿¹ç‚¹
        trajectories = sequence_result['trajectories']
        
        # å¤„ç†æ¯ä¸€å¸§
        for idx, frame in enumerate(frames):
            trajectory_frame = frame.copy()
            
            # ç»˜åˆ¶å½“å‰å¸§ä¹‹å‰çš„è½¨è¿¹
            for point_name in ['left_wrist', 'right_wrist']:
                if point_name not in trajectories:
                    continue
                
                traj = trajectories[point_name]
                color = (255, 0, 0) if 'left' in point_name else (0, 0, 255)
                
                # ç»˜åˆ¶è½¨è¿¹çº¿
                points_to_draw = []
                for i in range(min(idx + 1, len(traj['x']))):
                    x = traj['x'][i]
                    y = traj['y'][i]
                    vis = traj['visibility'][i]
                    
                    if x is not None and y is not None and vis > 0.5:
                        px = int(x * width)
                        py = int(y * height)
                        points_to_draw.append((px, py))
                
                # ç»˜åˆ¶è½¨è¿¹ç‚¹å’Œè¿çº¿
                for i in range(1, len(points_to_draw)):
                    # çº¿æ¡é€æ˜åº¦æ¸å˜
                    alpha = 0.3 + 0.7 * (i / max(1, len(points_to_draw) - 1))
                    cv2.line(trajectory_frame, points_to_draw[i-1], points_to_draw[i], 
                            color, 2)
                
                # å½“å‰ç‚¹åŠ ç²—æ˜¾ç¤º
                if len(points_to_draw) > 0:
                    cv2.circle(trajectory_frame, points_to_draw[-1], 8, color, -1)
            
            # ç»˜åˆ¶å½“å‰éª¨æ¶
            landmarks = sequence_result['frames_data'][idx]['landmarks']
            if landmarks:
                trajectory_frame = self._draw_skeleton(trajectory_frame, landmarks, 
                                                      point_color=(0, 255, 0),
                                                      line_color=(0, 255, 0),
                                                      point_radius=5,
                                                      line_thickness=2)
            
            # æ·»åŠ æ ‡é¢˜å’Œè¯´æ˜
            cv2.putText(trajectory_frame, "Motion Trajectory", 
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
            cv2.putText(trajectory_frame, f"Frame {idx + 1}/{len(frames)}", 
                       (10, height - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            
            # å›¾ä¾‹
            cv2.rectangle(trajectory_frame, (width - 150, 10), (width - 10, 80), (0, 0, 0), -1)
            cv2.putText(trajectory_frame, "Left Wrist", (width - 140, 35), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)
            cv2.putText(trajectory_frame, "Right Wrist", (width - 140, 60), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)
            
            # å†™å…¥å¸§ï¼ˆä¸æ£€æŸ¥è¿”å›å€¼ï¼‰
            out.write(trajectory_frame)
        
        # é‡Šæ”¾èµ„æº
        out.release()
        
        # éªŒè¯æ–‡ä»¶
        if not os.path.exists(output_path) or os.path.getsize(output_path) == 0:
            raise RuntimeError(f"è§†é¢‘æ–‡ä»¶ç”Ÿæˆå¤±è´¥: {output_path}")
        
        return output_path

